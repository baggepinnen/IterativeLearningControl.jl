var documenterSearchIndex = {"docs":
[{"location":"HeuristicILC/#HeuristicILC","page":"HeuristicILC","title":"HeuristicILC","text":"","category":"section"},{"location":"HeuristicILC/","page":"HeuristicILC","title":"HeuristicILC","text":"A heuristic ILC scheme that operates by adjusting the reference signal r typically looks something like this, at ILC iteration k:","category":"page"},{"location":"HeuristicILC/","page":"HeuristicILC","title":"HeuristicILC","text":"beginaligned\ny_k(t) = G_r(q) big(r(t) + a_k(t) big) \ne_k(t) = r(t) - y_k(t) \na_k(t) = Q(q) big( a_k-1(t) + L(q) e_k-1(t) big)\nendaligned","category":"page"},{"location":"HeuristicILC/","page":"HeuristicILC","title":"HeuristicILC","text":"where q is the time-shift operator, G_r(q) is the transfer function from the reference r to the output y, i.e, typically a closed-loop transfer function, e_k is the control error and a_k is the ILC adjustment signal, an additive correction to the reference that is learned throughout the ILC iterations in order to minimize the control error. Q(q) and L(q) are stable filters that control the learning dynamics. Interestingly, these filters does not have to be causal since they operate on the signals e and a between ILC iterations, when the whole signals are available at once for acausal filtering. ","category":"page"},{"location":"HeuristicILC/","page":"HeuristicILC","title":"HeuristicILC","text":"If the ILC instead operates by adding directly to the the plant input u, the first equation above is replaced by","category":"page"},{"location":"HeuristicILC/","page":"HeuristicILC","title":"HeuristicILC","text":"y_k(t) = G_r(q) r(t) + G_u(q) a_k(t)","category":"page"},{"location":"HeuristicILC/","page":"HeuristicILC","title":"HeuristicILC","text":"where the transfer function G_u(q) is the closed-loop transfer function from plant input to the output y.","category":"page"},{"location":"HeuristicILC/","page":"HeuristicILC","title":"HeuristicILC","text":"In simulation (the rollout y_k = G_r(q) (r + a_k) is simulated), this scheme is nothing other than an open-loop optimal-control strategy, while if y_k = G_r(q) (r + a_k) amounts to performing an actual experiment on a process, ILC turns into episode-based reinforcement learning or adaptive control.","category":"page"},{"location":"HeuristicILC/#Example","page":"HeuristicILC","title":"Example","text":"","category":"section"},{"location":"HeuristicILC/","page":"HeuristicILC","title":"HeuristicILC","text":"The system to control in this example is a double-mass system with a spring and damper in between. This system is a common model of a servo system where one mass represents the motor and the other represents the load. The spring and damper represents a flexible transmission between them. We will create two instances of the system model. P represents the nominal model, whereas P_act represents the actual (unknown) dynamics that may differ slightly from the model used for design. This simulates a model-based approach where there is a slight error in the model. The error will lie in the mass of the load, simulating, e.g., that the motor is driving a heavier load than specified. ","category":"page"},{"location":"HeuristicILC/","page":"HeuristicILC","title":"HeuristicILC","text":"We will also design a PID controller C with a filter for the system, the controller is poorly tuned and not very good at tracking fast reference steps, in practice, one would likely design a feedforward controller as well to improve upon this, but for now we'll stick with the simple feedback controller.","category":"page"},{"location":"HeuristicILC/#System-model-and-controller","page":"HeuristicILC","title":"System model and controller","text":"","category":"section"},{"location":"HeuristicILC/","page":"HeuristicILC","title":"HeuristicILC","text":"using Plots\ndefault(size=(800,800))","category":"page"},{"location":"HeuristicILC/","page":"HeuristicILC","title":"HeuristicILC","text":"using IterativeLearningControl, ControlSystemsBase, Plots\n\nfunction double_mass_model(; \n                Jm = 1,   # motor inertia\n                Jl = 1,   # load inertia\n                k  = 100, # stiffness\n                c0 = 1,   # motor damping\n                c1 = 1,   # transmission damping\n                c2 = 1,   # load damping\n)\n\n    A = [\n        0.0 1 0 0\n        -k/Jm -(c1 + c0)/Jm k/Jm c1/Jm\n        0 0 0 1\n        k/Jl c1/Jl -k/Jl -(c1 + c2)/Jl\n    ]\n    B = [0, 1/Jm, 0, 0]\n    C = [1 0 0 0]\n    ss(A, B, C, 0)\nend\n\n# Continuous\nP    = double_mass_model(Jl = 1)\nPact = double_mass_model(Jl = 1.5) # 50% more load than modeled\nC    = pid(10, 1, 1, form = :series) * tf(1, [0.02, 1])","category":"page"},{"location":"HeuristicILC/#Discretization","page":"HeuristicILC","title":"Discretization","text":"","category":"section"},{"location":"HeuristicILC/","page":"HeuristicILC","title":"HeuristicILC","text":"The system model and controller above are both continuous-time. We discretize them using a sample time of T_s = 002 seconds. We also create discrete-time versions of the closed-loop system fom reference r to output y, G_r, and from plant input u to output, G_u. Forming closed-loop systems is done using the feedback function, which takes the direct path between input and output as the first argument and the feedback path as the second argument (defaults to 1 if omitted). The call feedback(P*C) thus forms the transfer function PC  (1 + PC) while feedback(P, C) forms the transfer function P  (1 + PC).","category":"page"},{"location":"HeuristicILC/","page":"HeuristicILC","title":"HeuristicILC","text":"\nTs = 0.02 # Sample time\nGr = c2d(feedback(P*C), Ts)       |> tf\nGu = c2d(feedback(P, C), Ts)\nGract = c2d(feedback(Pact*C), Ts)\nGuact = c2d(feedback(Pact, C), Ts)\n\nbodeplot([Gr, Gract], lab=[\"G model\" \"G actual\"], plotphase=false)","category":"page"},{"location":"HeuristicILC/","page":"HeuristicILC","title":"HeuristicILC","text":"The Bode plot above shows the closed-loop transfer function from reference r to output y, both using the model P and the \"actual\" plant Pact.","category":"page"},{"location":"HeuristicILC/#Reference-trajectory","page":"HeuristicILC","title":"Reference trajectory","text":"","category":"section"},{"location":"HeuristicILC/","page":"HeuristicILC","title":"HeuristicILC","text":"Next up we design a reference trajectory and simulate the actual closed-loop dynamics.","category":"page"},{"location":"HeuristicILC/","page":"HeuristicILC","title":"HeuristicILC","text":"T = 3pi    # Duration\nt = 0:Ts:T # Time vector\nfunction funnysin(t)\n    x = sin(t)\n    s,a = sign(x), abs(x)\n    y = s*((a + 0.01)^0.2 - 0.01^0.2)\n    t > 2π ? sign(y) : y\nend\nr = funnysin.(t)' |> Array # Reference signal\n\nres = lsim(Gract, r, t)\nplot(res, plotu=true, layout=1, sp=1, title=\"Closed-loop simulation with actual dynamics\", lab=[\"y\" \"r\"])","category":"page"},{"location":"HeuristicILC/","page":"HeuristicILC","title":"HeuristicILC","text":"Performance is poor.. Enter ILC!","category":"page"},{"location":"HeuristicILC/#Choosing-filters","page":"HeuristicILC","title":"Choosing filters","text":"","category":"section"},{"location":"HeuristicILC/","page":"HeuristicILC","title":"HeuristicILC","text":"The next step is to define the ILC filters Q(z) and L(z).","category":"page"},{"location":"HeuristicILC/","page":"HeuristicILC","title":"HeuristicILC","text":"The filter L(q) acts as a frequency-dependent step size. To make the procedure take smaller steps, simply scale L by a constant < 1. Scaling down L makes the learning process slower but more robust. A heuristic choice of L is some form of scaled lookahead, such as 05z^l where l geq 0 is the number of samples lookahead. A model-based approach may use some form of inverse of the system model, which is what we will use here. [nonlinear]","category":"page"},{"location":"HeuristicILC/","page":"HeuristicILC","title":"HeuristicILC","text":"[nonlinear]: Inverse models can be formed also for some nonlinear systems. ModelingToolkit.jl is particularly well suited for inverting models due to its acausal nature.","category":"page"},{"location":"HeuristicILC/","page":"HeuristicILC","title":"HeuristicILC","text":"The filter Q(z) acts to make the procedure robust w.r.t. noise and modeling errors. Q has a final say over what frequencies appear in a and it's good to choose Q with low-pass properties. Q will here be applied in zero-phase mode, so the effective transfer function will be Q(z)Q(z).","category":"page"},{"location":"HeuristicILC/","page":"HeuristicILC","title":"HeuristicILC","text":"z = tf(\"z\", Ts)\nQ = c2d(tf(1, [0.05, 1]), Ts)\n# L = 0.9z^1 # A more conservative and heuristic choice\nL = 0.5inv(Gr) # Make the scaling factor smaller to take smaller steps\n\nalg = HeuristicILC(Q, L, :ref)\nnothing # hide","category":"page"},{"location":"HeuristicILC/","page":"HeuristicILC","title":"HeuristicILC","text":"A theorem due to Norrlöf says that for the ILC iterations to converge, one needs to satisfy  1 - LG   Q^-1 which we can verify by looking at the Bode curves of the two sides of the inequality","category":"page"},{"location":"HeuristicILC/","page":"HeuristicILC","title":"HeuristicILC","text":"ilc_theorem(alg, Gr, tf(Gract))","category":"page"},{"location":"HeuristicILC/","page":"HeuristicILC","title":"HeuristicILC","text":"Above, we plotted this curve also for the actual dynamics. This is of course not possible in a real scenario where this is unknown, but one could plot it for multiple plausible models and verify that they are all below the boundary. See Uncertainty modeling using RobustAndOptimalControl.jl for guidance on this. Looking at the stability condition, it becomes obvious how making Q small where the model is uncertain is beneficial for robustness of the ILC scheme.","category":"page"},{"location":"HeuristicILC/#ILC-iteration","page":"HeuristicILC","title":"ILC iteration","text":"","category":"section"},{"location":"HeuristicILC/","page":"HeuristicILC","title":"HeuristicILC","text":"The next step is to implement the ILC scheme and run it using the function ilc:","category":"page"},{"location":"HeuristicILC/","page":"HeuristicILC","title":"HeuristicILC","text":"prob = ILCProblem(; r, Gr, Gu)\nsol = ilc(prob, alg)\nplot(sol)","category":"page"},{"location":"HeuristicILC/","page":"HeuristicILC","title":"HeuristicILC","text":"When running on the model, the result looks very good. We see that the tracking error in the last plot decreases rapidly and is much smaller after only a couple of iterations. We also note that the adjusted reference r+a has effectively been phase-advanced slightly to compensate for the lag in the system dynamics. This is an effect of the acausal filtering due to L = G_C^-1.","category":"page"},{"location":"HeuristicILC/","page":"HeuristicILC","title":"HeuristicILC","text":"How does it work on the \"actual\" dynamics? To simulate the effect of plant-model mismatch, one may provide a different instance of the ILCProblem using the actual keyword argument which is used to simulate the plant response. The ILC update will be performed using the plant model from prob, while simulated data will be acquired from the models in actual.","category":"page"},{"location":"HeuristicILC/","page":"HeuristicILC","title":"HeuristicILC","text":"actual = ILCProblem(; r, Gr=Gract, Gu=Guact)\nsol = ilc(prob, alg; actual)\nplot(sol)","category":"page"},{"location":"HeuristicILC/","page":"HeuristicILC","title":"HeuristicILC","text":"The result is subtly worse, but considering the rather big model error the result is still quite good. ","category":"page"},{"location":"HeuristicILC/#Assessing-convergence-under-uncertainty","page":"HeuristicILC","title":"Assessing convergence under uncertainty","text":"","category":"section"},{"location":"HeuristicILC/","page":"HeuristicILC","title":"HeuristicILC","text":"We can attempt at modeling the uncertainty we have in the plant using uncertain numbers from MonteCarloMeasurements.jl. This will allow us to asses whether our chosen filter fulfil the convergence criteria for all possible realizations of the uncertain plant.","category":"page"},{"location":"HeuristicILC/","page":"HeuristicILC","title":"HeuristicILC","text":"using MonteCarloMeasurements\nunsafe_comparisons(true)\nPact = double_mass_model(\n    Jl = 0.5..1.5, # ± 50% load uncertainty\n    c1 = 0.8..1.2, # ± 20% transmission damping uncertainty\n    c2 = 0.8..1.2, # ± 20% load damping uncertainty\n) \nGract = c2d(feedback(Pact*C), Ts)\nw = exp10.(-2:0.01:2)\nilc_theorem(alg, Gr, tf(Gract); w)","category":"page"},{"location":"HeuristicILC/","page":"HeuristicILC","title":"HeuristicILC","text":"In this case, it looks like we're good to go!","category":"page"},{"location":"HeuristicILC/","page":"HeuristicILC","title":"HeuristicILC","text":"Learn more about modeling uncertainty in control systems under RobustAndOptimalControl: Uncertainty modeling.","category":"page"},{"location":"HeuristicILC/#Docstring","page":"HeuristicILC","title":"Docstring","text":"","category":"section"},{"location":"HeuristicILC/","page":"HeuristicILC","title":"HeuristicILC","text":"HeuristicILC","category":"page"},{"location":"HeuristicILC/#IterativeLearningControl.HeuristicILC","page":"HeuristicILC","title":"IterativeLearningControl.HeuristicILC","text":"HeuristicILC(  Q, L, location)        # Positional arguments\nHeuristicILC(; Q, L, location = :ref) # Keyword arguments\n\nApply the learning rule\n\nbeginaligned\ny_k(t) = G_r(q) big(r(t) + a_k(t) big) \ne_k(t) = r(t) - y_k(t) \na_k(t) = Q(q) big( a_k-1(t) + L(q) e_k-1(t) big)\nendaligned\n\nIf location = :input, the first equation above is replaced by\n\ny_k(t) = G_r(q) r(t) + G_u(q) a_k(t)\n\nA theorem due to Norrlöf says that for this ILC iterations to converge, one needs to satisfy\n\n 1 - LG   Q^-1\n\nwhich we can verify by looking at the plot produced by the ilc_theorem function.\n\nFields:\n\nQ(z): Robustness filter (discrete time). The filter will be applied both forwards and backwards in time (like filtfilt), and the effective filter transfer funciton is thus Q(z)Q(z).\nL(z): Learning filter (discrete time). This filter may be non-causal, for example L = G^-1 where G is the closed-loop transfer function.\nlocation: Either :ref or :input. If :ref, the ILC input is added to the reference signal, otherwise it is added to the input signal directly.\n\n\n\n\n\n","category":"type"},{"location":"OptimizationILC/#OptimizationILC","page":"OptimizationILC","title":"OptimizationILC","text":"","category":"section"},{"location":"OptimizationILC/","page":"OptimizationILC","title":"OptimizationILC","text":"This ILC algorithm is derived by considering the optimization problem","category":"page"},{"location":"OptimizationILC/","page":"OptimizationILC","title":"OptimizationILC","text":"operatornamemin_a_k+1 J_k+1 = e_k+1^T e_k+1 + ρ a_k+1^T a_k+1","category":"page"},{"location":"OptimizationILC/","page":"OptimizationILC","title":"OptimizationILC","text":"subject to","category":"page"},{"location":"OptimizationILC/","page":"OptimizationILC","title":"OptimizationILC","text":"a_k+1-a_k_2^2  delta","category":"page"},{"location":"OptimizationILC/","page":"OptimizationILC","title":"OptimizationILC","text":"Internally, a system model on Hankel-operator form is used, that is, the linear system is represented as a matrix operator T_a consisting of shifted impulse responses such that the relation between the ILC adjustment signal a and the output y is given by","category":"page"},{"location":"OptimizationILC/","page":"OptimizationILC","title":"OptimizationILC","text":"y = T_a a","category":"page"},{"location":"OptimizationILC/","page":"OptimizationILC","title":"OptimizationILC","text":"After some derivations, available in Norrlöf's thesis, a simple algorithm is obtained that relies on only matrix factorizations:","category":"page"},{"location":"OptimizationILC/","page":"OptimizationILC","title":"OptimizationILC","text":"Q = ((ρ+λ)*I + Ta'Ta)\\(λ*I + Ta'Ta)\nL = (λ*I + Ta'Ta)\\Ta'\na[k+1] = (Q*(a[k]' + L*e'))'","category":"page"},{"location":"OptimizationILC/","page":"OptimizationILC","title":"OptimizationILC","text":"where the tuning variable λ is used to control the learning rate, and ρ is used to control the trade-off between the control error e and control effort a.","category":"page"},{"location":"OptimizationILC/#Example","page":"OptimizationILC","title":"Example","text":"","category":"section"},{"location":"OptimizationILC/","page":"OptimizationILC","title":"OptimizationILC","text":"This example mirrors that of HeuristicILC, we create the system model and feedback controller here without any explanation, and refer to the HeuristicILC example for those details","category":"page"},{"location":"OptimizationILC/","page":"OptimizationILC","title":"OptimizationILC","text":"using IterativeLearningControl, ControlSystemsBase, Plots\n\nfunction double_mass_model(; \n                Jm = 1,   # motor inertia\n                Jl = 1,   # load inertia\n                k  = 100, # stiffness\n                c0 = 1,   # motor damping\n                c1 = 1,   # transmission damping\n                c2 = 1,   # load damping\n)\n\n    A = [\n        0.0 1 0 0\n        -k/Jm -(c1 + c0)/Jm k/Jm c1/Jm\n        0 0 0 1\n        k/Jl c1/Jl -k/Jl -(c1 + c2)/Jl\n    ]\n    B = [0, 1/Jm, 0, 0]\n    C = [1 0 0 0]\n    ss(A, B, C, 0)\nend\n\n# Continuous\nP    = double_mass_model(Jl = 1)\nPact = double_mass_model(Jl = 1.5) # 50% more load than modeled\nC    = pid(10, 1, 1, form = :series) * tf(1, [0.02, 1])\n\nTs = 0.02 # Sample time\nGr = c2d(feedback(P*C), Ts)       |> tf\nGu = c2d(feedback(P, C), Ts)\nGract = c2d(feedback(Pact*C), Ts)\nGuact = c2d(feedback(Pact, C), Ts)\n\nT = 3pi    # Duration\nt = 0:Ts:T # Time vector\nfunction funnysin(t)\n    x = sin(t)\n    s,a = sign(x), abs(x)\n    y = s*((a + 0.01)^0.2 - 0.01^0.2)\n    t > 2π ? sign(y) : y\nend\nr = funnysin.(t)' |> Array # Reference signal","category":"page"},{"location":"OptimizationILC/","page":"OptimizationILC","title":"OptimizationILC","text":"Next, we define the ILCProblem and create the learning algorithm object OptimizationILC","category":"page"},{"location":"OptimizationILC/","page":"OptimizationILC","title":"OptimizationILC","text":"prob = ILCProblem(; r, Gr, Gu)\nalg = OptimizationILC(; ρ=0.00001, λ=0.0001)\nsol = ilc(prob, alg)\nplot(sol)","category":"page"},{"location":"OptimizationILC/","page":"OptimizationILC","title":"OptimizationILC","text":"The result looks good when run on the model, but how does it looks if we run it on the \"actual\" dynamics with 50% larger load inertia?","category":"page"},{"location":"OptimizationILC/","page":"OptimizationILC","title":"OptimizationILC","text":"actual = ILCProblem(; r, Gr=Gract, Gu=Guact)\nsol = ilc(prob, alg; actual)\nplot(sol)","category":"page"},{"location":"OptimizationILC/","page":"OptimizationILC","title":"OptimizationILC","text":"Still quite good. The resulting ILC feedforward signal a in this example is not immediately comparable to that from the HeuristicILC example. Here, we let the ILC signal enter directly at the plant input, while in the HeuristicILC example, the ILC signal was added to the reference signal.","category":"page"},{"location":"OptimizationILC/#Docstring","page":"OptimizationILC","title":"Docstring","text":"","category":"section"},{"location":"OptimizationILC/","page":"OptimizationILC","title":"OptimizationILC","text":"OptimizationILC","category":"page"},{"location":"OptimizationILC/#IterativeLearningControl.OptimizationILC","page":"OptimizationILC","title":"IterativeLearningControl.OptimizationILC","text":"OptimizationILC(; ρ = 1e-3, λ = 1e-3)\n\nOptimization-based linear ILC algorithm from Norrlöf's thesis. This algorithm applies the ILC feedforward signal directly to the plant input.\n\nArguments:\n\nρ: Penalty on feedforward control action\nλ: Step size penalty\n\n\n\n\n\n","category":"type"},{"location":"GradientILC/#GradientILC","page":"GradientILC","title":"GradientILC","text":"","category":"section"},{"location":"GradientILC/","page":"GradientILC","title":"GradientILC","text":"This ILC scheme uses a model, linear or nonlinear, SISO or MIMO, to compute the gradient of a quadratic cost model","category":"page"},{"location":"GradientILC/","page":"GradientILC","title":"GradientILC","text":"operatornamemin_a J = e^T e","category":"page"},{"location":"GradientILC/","page":"GradientILC","title":"GradientILC","text":"The update to the ILC adjustment signal a is then computed as","category":"page"},{"location":"GradientILC/","page":"GradientILC","title":"GradientILC","text":"a_k+1 = a_k + β H^T e_k","category":"page"},{"location":"GradientILC/","page":"GradientILC","title":"GradientILC","text":"The parameter beta is the learning step size, H is the Jacobian of the plant output w.r.t. a and e is the tracking error.","category":"page"},{"location":"GradientILC/","page":"GradientILC","title":"GradientILC","text":"The ILC update rule above highlights the similarity between this scheme and a simple gradient-descent algorithm to solve an optimal control problem, the only difference is whether the tracking error e comes from a simulation (optimal control) or from an experiment on a physical system (ILC). The cost model can also be trivially modified to include a penalty on the size of the adjustment signal a.","category":"page"},{"location":"GradientILC/","page":"GradientILC","title":"GradientILC","text":"A model-free version of this algorithm exists, see ModelFreeILC.","category":"page"},{"location":"GradientILC/#Example","page":"GradientILC","title":"Example","text":"","category":"section"},{"location":"GradientILC/","page":"GradientILC","title":"GradientILC","text":"This example mirrors that of HeuristicILC, we create the system model and feedback controller here without any explanation, and refer to the HeuristicILC example for those details","category":"page"},{"location":"GradientILC/","page":"GradientILC","title":"GradientILC","text":"using IterativeLearningControl, ControlSystemsBase, Plots\n\nfunction double_mass_model(; \n                Jm = 1,   # motor inertia\n                Jl = 1,   # load inertia\n                k  = 100, # stiffness\n                c0 = 1,   # motor damping\n                c1 = 1,   # transmission damping\n                c2 = 1,   # load damping\n)\n\n    A = [\n        0.0 1 0 0\n        -k/Jm -(c1 + c0)/Jm k/Jm c1/Jm\n        0 0 0 1\n        k/Jl c1/Jl -k/Jl -(c1 + c2)/Jl\n    ]\n    B = [0, 1/Jm, 0, 0]\n    C = [1 0 0 0]\n    ss(A, B, C, 0)\nend\n\n# Continuous\nP    = double_mass_model(Jl = 1)\nPact = double_mass_model(Jl = 1.5) # 50% more load than modeled\nC    = pid(10, 1, 1, form = :series) * tf(1, [0.02, 1])\n\nTs = 0.02 # Sample time\nGr = c2d(feedback(P*C), Ts)       |> tf\nGu = c2d(feedback(P, C), Ts)\nGract = c2d(feedback(Pact*C), Ts)\nGuact = c2d(feedback(Pact, C), Ts)\n\nT = 3pi    # Duration\nt = 0:Ts:T # Time vector\nfunction funnysin(t)\n    x = sin(t)\n    s,a = sign(x), abs(x)\n    y = s*((a + 0.01)^0.2 - 0.01^0.2)\n    t > 2π ? sign(y) : y\nend\nr = funnysin.(t)' |> Array # Reference signal","category":"page"},{"location":"GradientILC/","page":"GradientILC","title":"GradientILC","text":"Next, we define the ILCProblem and create the learning algorithm object OptimizationILC","category":"page"},{"location":"GradientILC/","page":"GradientILC","title":"GradientILC","text":"prob = ILCProblem(; r, Gr, Gu)\nactual = ILCProblem(; r, Gr=Gract, Gu=Guact)\n\nalg = GradientILC(500)\nsol = ilc(prob, alg; iters=5)\nplot(sol)","category":"page"},{"location":"GradientILC/","page":"GradientILC","title":"GradientILC","text":"The result looks good, how about when run on the \"actual\" dynamics with 50% larger load inertia?","category":"page"},{"location":"GradientILC/","page":"GradientILC","title":"GradientILC","text":"sol = ilc(prob, alg; actual, iters=5)\nplot(sol)","category":"page"},{"location":"GradientILC/","page":"GradientILC","title":"GradientILC","text":"Still pretty good.","category":"page"},{"location":"GradientILC/#Docstring","page":"GradientILC","title":"Docstring","text":"","category":"section"},{"location":"GradientILC/","page":"GradientILC","title":"GradientILC","text":"GradientILC","category":"page"},{"location":"GradientILC/#IterativeLearningControl.GradientILC","page":"GradientILC","title":"IterativeLearningControl.GradientILC","text":"GradientILC(β)\n\nA model-based gradient ILC scheme that works for linear or nonlinear systems. The ILC update rule is\n\na_k+1(t) = a_k(t) + β H^T e_k(t)\n\nwhere H is the Jacobian of the plant output w.r.t. a and β is the step size.\n\nFor non-square MIMO systems, this algorithm can only operate on the reference signal, i.e., with G_u = G_r in the ILCProblem. This is because the algorithm adds a scaled version of the tracking error to the ILC adjustment signal, and the two must thus be of compatible dimensions.\n\nA model-free version of this algorithm is implemented in ModelFreeILC.\n\nFields:\n\nβ::Float64: Step size (learning rate)\n\n\n\n\n\n","category":"type"},{"location":"api/#Exported-functions-and-types","page":"API","title":"Exported functions and types","text":"","category":"section"},{"location":"api/#Index","page":"API","title":"Index","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"","category":"page"},{"location":"api/#Docstrings","page":"API","title":"Docstrings","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"ILCProblem\nIterativeLearningControl.ILCSolution","category":"page"},{"location":"api/#IterativeLearningControl.ILCProblem","page":"API","title":"IterativeLearningControl.ILCProblem","text":"ILCProblem\n\nFields:\n\nr: Reference signal, a matrix of size (ny, N) where ny is the number of outputs and N is the number of time points.\nGr: Closed-loop transfer function from reference to output. May be either an LTISystem model from ControlSystemsBase, such as those created using tf or ss, or an LTVSystem model.\nGu: Closed-loop transfer function from plant input to output\n\n\n\n\n\n","category":"type"},{"location":"api/#IterativeLearningControl.ILCSolution","page":"API","title":"IterativeLearningControl.ILCSolution","text":"ILCSolution\n\nA structure representing the solution to an ILC problem. \n\nFields:\n\nY: Plant responses. Y[i] is the response during the ith iteration. The first response is recorded before any ILC input is applied, while the last response is recorded before the last ILC adjustment signal has been computed, i.e., Y[end] corresponds to the response to the ILC input A[end-1].\nE: Errors. E[i] is the error during the ith iteration, i.e., E[i] = r - Y[i] where r is the reference signal.\nA: ILC inputs. A[i] is the ILC input during the ith iteration.\nprob: The ILCProblem that was solved\nalg: The ILCAlgorithm that was used\n\n\n\n\n\n","category":"type"},{"location":"api/","page":"API","title":"API","text":"Modules = [IterativeLearningControl]\nOrder = [:function]","category":"page"},{"location":"api/#ControlSystemsBase.linearize-Tuple{NonlinearSystem, AbstractMatrix, AbstractMatrix, Any, Any, Vararg{Any}}","page":"API","title":"ControlSystemsBase.linearize","text":"linearize(m::NonlinearSystem, x0::AbstractMatrix, a0::AbstractMatrix, r, p)\n\nLinearizes a nonlinear system m around the trajectory defined by x0, a0, r, and p. The resulting linear time-varying (LTV) system is returned.\n\nArguments\n\nm::NonlinearSystem: The nonlinear system to be linearized.\nx0::AbstractMatrix: The state matrix of size (nx, N) where nx is the number of states and N is the number of time points.\na0::AbstractMatrix: The input matrix of size (na, N) where na is the number of adjustment inputs.\nr: The reference signal matrix.\np: The parameter object.\n\n\n\n\n\n","category":"method"},{"location":"api/#ControlSystemsBase.linearize-Tuple{NonlinearSystem, AbstractVector, AbstractVector, Vararg{Any}}","page":"API","title":"ControlSystemsBase.linearize","text":"linearize(m::NonlinearSystem, x0::AbstractVector, a0::AbstractVector, args...)\n\nLinearize a nonlinear system m around the operating point (x0, a0).\n\nArguments\n\nm::NonlinearSystem: The nonlinear system to be linearized.\nx0::AbstractVector: The operating point of the state variables.\na0::AbstractVector: The operating point of the ILC input variables.\nargs...: Additional arguments to be passed to the dynamics functions (such as r, p, t).\n\nReturns\n\nAn instance of ControlSystemsBase.StateSpace representing the linearized system.\n\n\n\n\n\n","category":"method"},{"location":"api/#IterativeLearningControl.compute_input-Tuple{Any, HeuristicILC, Any, Any, Any}","page":"API","title":"IterativeLearningControl.compute_input","text":"compute_input(prob, alg::ILCAlgorithm, workspace, a, e)\n\nCompute the next ILC input using the learning rule\n\nArguments:\n\nalg: The ILC algorithm\nworkspace: A workspace created by calling init on the algorithm: workspace = init(prob, alg).\na: Previous ILC input\ne: Error r - y\n\n\n\n\n\n","category":"method"},{"location":"api/#IterativeLearningControl.hankel_operator-Tuple{LTISystem{<:Discrete}, Int64}","page":"API","title":"IterativeLearningControl.hankel_operator","text":"hankel(sys::LTISystem{<:Discrete}, N::Int)\n\nReturn a matrix operator H such that Hu^T = y^T where y = lsim(sys, u). H is a Hankel matrix containing the Markov parameters of the system (scaled impulse response).\n\n\n\n\n\n","category":"method"},{"location":"api/#IterativeLearningControl.hv-Tuple{Any}","page":"API","title":"IterativeLearningControl.hv","text":"A little helper function that takes a matrix with dimensions (nsignals, n_timepoints) and returns a reshaped vector version that is suitable for multiplying the Hankel operator obtained by calling hankel_operator or mv_hankel_operator.\n\n\n\n\n\n","category":"method"},{"location":"api/#IterativeLearningControl.ilc-Tuple{Any, Any}","page":"API","title":"IterativeLearningControl.ilc","text":"ilc(prob, alg; iters = 5, actual=prob)\n\nRun the ILC algorithm for iters iterations. Returns a ILCSolution structure.\n\nTo manually perform ILC iterations, see the functions\n\ninit\ncompute_input\n\nTo simulate the effect of plant-model mismatch, one may provide a different instance of the ILCProblem using the actual keyword argument which is used to simulate the plant response. The ILC update will be performed using the plant model from prob, while simulated data will be acquired from the plant models in the actual problem.\n\n\n\n\n\n","category":"method"},{"location":"api/#IterativeLearningControl.ilc_theorem","page":"API","title":"IterativeLearningControl.ilc_theorem","text":"ilc_theorem(alg::HeuristicILC, Gc, Gcact = nothing)\n\nPlot the stability boundary for the ILC algorithm.\n\nArguments:\n\nalg: Containing the filters Q and L\nGc: The closed-loop system from ILC signal to output. If alg.location = :ref, this is typically given by feedback(P*C) while if alg.location = :input, this is typically given by feedback(P, C).\nGcact: If provided, this is the \"actual\" closed-loop system which may be constructed using a different plant model than Gc. This is useful when trying to determine if the filter choises will lead to a robust ILC algorithm. Gc may be constructed using, e.g., uncertain parameters, see https://juliacontrol.github.io/RobustAndOptimalControl.jl/dev/uncertainty/ for more details.\n\n\n\n\n\n","category":"function"},{"location":"api/#IterativeLearningControl.init-Tuple{Any, Any}","page":"API","title":"IterativeLearningControl.init","text":"workspace = init(prob, alg)\n\nInitialize the ILC algorithm. This function is called internally by the funciton ilc but manual iterations require the user to initialize the workspace explicitly.\n\n\n\n\n\n","category":"method"},{"location":"api/#IterativeLearningControl.mv_hankel_operator","page":"API","title":"IterativeLearningControl.mv_hankel_operator","text":"mv_hankel_operator(sys::LTISystem{<:Discrete}, N::Int)\n\nReturn a matrix operator H such that y == reshape(H*vec(u'), :, sys.ny)' where y = lsim(sys, u). H is a block Hankel matrix containing the Markov parameters of the system (scaled impulse response).\n\nUse of this function requires the user to manually install and load the packages using JuMP, BlockArrays.\n\n\n\n\n\n","category":"function"},{"location":"ConstrainedILC/#ConstrainedILC","page":"ConstrainedILC","title":"ConstrainedILC","text":"","category":"section"},{"location":"ConstrainedILC/","page":"ConstrainedILC","title":"ConstrainedILC","text":"This algorithm uses a quadratic program to solve the ILC problem subject to constraints on the adjustment signal a and the plant output y. ","category":"page"},{"location":"ConstrainedILC/","page":"ConstrainedILC","title":"ConstrainedILC","text":"The algorithm comes from the paper On Robustness in Optimization-Based Constrained Iterative Learning Control and considers an LQR style optimization problem","category":"page"},{"location":"ConstrainedILC/","page":"ConstrainedILC","title":"ConstrainedILC","text":"operatornamemin_a_k+1 J_k+1 = e_k+1^T Q e_k+1 + a_k+1^T R a_k+1","category":"page"},{"location":"ConstrainedILC/","page":"ConstrainedILC","title":"ConstrainedILC","text":"subject to constraints on a and y.","category":"page"},{"location":"ConstrainedILC/","page":"ConstrainedILC","title":"ConstrainedILC","text":"The optimization problem is internally modeled using JuMP and will, if the user-provided constraints are linear, end up as a quadratic program. However, the user may supply arbitrary constraints supported by JuMP, in which case a supporting optimization solver must be used. Below, we use the QP solver OSQP.","category":"page"},{"location":"ConstrainedILC/","page":"ConstrainedILC","title":"ConstrainedILC","text":"note: Note\nThis algorithm is only available if the user has manually installed and loaded the packages JuMP and BlockArrays. The user must additionally install a solver compatible with the modeled optimization problem. If only linear constraints are used, we recommend OSQP.","category":"page"},{"location":"ConstrainedILC/#Constraints","page":"ConstrainedILC","title":"Constraints","text":"","category":"section"},{"location":"ConstrainedILC/","page":"ConstrainedILC","title":"ConstrainedILC","text":"The constraints are added by providing two functions to the constructor of ConstrainedILC. Each of these functions take a JuMP model as well as a JuMP optimization variable as input. The user then adds the desired constraints that applies to the variable in the function. For example, to add constraints to the adjustment signal -25  a  25, we create the function","category":"page"},{"location":"ConstrainedILC/","page":"ConstrainedILC","title":"ConstrainedILC","text":"A = function (model, a)\n    lower,upper = -25ones(Gu.nu), 25ones(Gu.nu)\n    JuMP.@constraint(model, [i=1:size(v, 2)], lower .<= a[:, i] .<= upper)\nend","category":"page"},{"location":"ConstrainedILC/","page":"ConstrainedILC","title":"ConstrainedILC","text":"Similarly, we may add constraints on the outputs y by providing a similar function Y.","category":"page"},{"location":"ConstrainedILC/","page":"ConstrainedILC","title":"ConstrainedILC","text":"To constrain the total plant input, i.e., the sum of the contributions from ILC feedforward and feedback control, we create a constrained system that as the signals that we wish to constrain as outputs, and we can thus add these constraints as output constraints. If such a constrained output system is not supplied, it is assumed that the default plant output is constrained.","category":"page"},{"location":"ConstrainedILC/#Example","page":"ConstrainedILC","title":"Example","text":"","category":"section"},{"location":"ConstrainedILC/","page":"ConstrainedILC","title":"ConstrainedILC","text":"This example mirrors that of HeuristicILC, we create the system model and feedback controller here without any explanation, and refer to the HeuristicILC example for those details","category":"page"},{"location":"ConstrainedILC/","page":"ConstrainedILC","title":"ConstrainedILC","text":"using IterativeLearningControl, ControlSystemsBase, Plots\n\nfunction double_mass_model(; \n                Jm = 1,   # motor inertia\n                Jl = 1,   # load inertia\n                k  = 100, # stiffness\n                c0 = 1,   # motor damping\n                c1 = 1,   # transmission damping\n                c2 = 1,   # load damping\n)\n\n    A = [\n        0.0 1 0 0\n        -k/Jm -(c1 + c0)/Jm k/Jm c1/Jm\n        0 0 0 1\n        k/Jl c1/Jl -k/Jl -(c1 + c2)/Jl\n    ]\n    B = [0, 1/Jm, 0, 0]\n    C = [1 0 0 0]\n    ss(A, B, C, 0)\nend\n\n# Continuous\nP    = double_mass_model(Jl = 1)\nPact = double_mass_model(Jl = 1.5) # 50% more load than modeled\nC    = pid(10, 1, 1, form = :series) * tf(1, [0.02, 1])\n\nTs = 0.02 # Sample time\nGr = c2d(feedback(P*C), Ts)       |> tf\nGu = c2d(feedback(P, C), Ts)\nGract = c2d(feedback(Pact*C), Ts)\nGuact = c2d(feedback(Pact, C), Ts)\n\nT = 3pi    # Duration\nt = 0:Ts:T # Time vector\nfunction funnysin(t)\n    x = sin(t)\n    s,a = sign(x), abs(x)\n    y = s*((a + 0.01)^0.2 - 0.01^0.2)\n    t > 2π ? sign(y) : y\nend\nr = funnysin.(t)' |> Array # Reference signal","category":"page"},{"location":"ConstrainedILC/","page":"ConstrainedILC","title":"ConstrainedILC","text":"Next, we define the ILCProblem and create the learning algorithm object ConstrainedILC.","category":"page"},{"location":"ConstrainedILC/","page":"ConstrainedILC","title":"ConstrainedILC","text":"Here, we constrain the ILC input -25  a  25 and the plant output -11  y  11. We also use the QP solver OSQP. The weight matrices that penalize the control error, Q, and the control effort, R, are also supplied. α is a learning-rate parameter and this must be smaller than 2. The default value is 0.5.","category":"page"},{"location":"ConstrainedILC/","page":"ConstrainedILC","title":"ConstrainedILC","text":"We finally run the ILC iterations using the function ilc and plot the result.","category":"page"},{"location":"ConstrainedILC/","page":"ConstrainedILC","title":"ConstrainedILC","text":"using JuMP, BlockArrays, OSQP, LinearAlgebra\n\nprob = ILCProblem(; r, Gr, Gu)\n\nQ = 1000I(Gr.ny)\nR = 0.001I(Gu.nu)\n\nA = function (model, v)\n    lower,upper = -25ones(Gu.nu), 25ones(Gu.nu)\n    JuMP.@constraint(model, [i=1:size(v, 2)], lower .<= v[:, i] .<= upper)\nend\n\nY = function (model, yh)\n    lower,upper = -1.1ones(Gr.ny), 1.1ones(Gr.ny)\n    JuMP.@constraint(model, [i=1:size(yh, 2)], lower .<= yh[:, i] .<= upper)\nend\n\nalg = ConstrainedILC(; Q, R, A, Y, opt=OSQP.Optimizer, verbose=true, α=1)\nsol = ilc(prob, alg)\nplot(sol); hline!([1.1], l=(:red, :dash), sp=1, lab=\"Constraint\")","category":"page"},{"location":"ConstrainedILC/","page":"ConstrainedILC","title":"ConstrainedILC","text":"We see that the output constraint is violated in the first iteration. This is expected since the optimizer hasn't yet been run while this experiment was performed. Subsequent iterations respect the constraint. ","category":"page"},{"location":"ConstrainedILC/","page":"ConstrainedILC","title":"ConstrainedILC","text":"The result looks good when run on the model, but how does it looks if we run it on the \"actual\" dynamics with 50% larger load inertia?","category":"page"},{"location":"ConstrainedILC/","page":"ConstrainedILC","title":"ConstrainedILC","text":"actual = ILCProblem(; r, Gr=Gract, Gu=Guact)\nsol = ilc(prob, alg; actual)\nplot(sol); hline!([1.1], l=(:red, :dash), sp=1, lab=\"Constraint\")","category":"page"},{"location":"ConstrainedILC/","page":"ConstrainedILC","title":"ConstrainedILC","text":"Still quite good, but we do not quite satisfy the output constraint until after 4 iterations. The paper from which the algorithm is taken contains additional considerations required for robust constraint satisfaction under bounded disturbances and model uncertainty. These are not implemented here, but we encourage the interested reader to read the paper and consider the package LazySets.jl for the required computations of constraint sets, in particular, the Minkowski difference.","category":"page"},{"location":"ConstrainedILC/#Constraining-the-total-control-input","page":"ConstrainedILC","title":"Constraining the total control input","text":"","category":"section"},{"location":"ConstrainedILC/","page":"ConstrainedILC","title":"ConstrainedILC","text":"Above, we placed a constraint on the ILC adjustment signal a, but no constraint on the total control signal including the contribution of the feedback controller. Below, we create an augmented system that includes this signal as output, and then constrain this as an output constraint. The transfer function from reference to control signal is C(1+PC), while the transfer function from a feedforward signal added directly to the plant input to the total plant input is given by the (input) complementary sensitivity function CP  (1 + CP). We constrain the total control signal to be -500  u  500, and thus modify the Y function from above to include this constraint:","category":"page"},{"location":"ConstrainedILC/","page":"ConstrainedILC","title":"ConstrainedILC","text":"Gr_constraints = [Gr; c2d(feedback(C, P), Ts)] # Add output signal corresponding to the total control signal\nGu_constraints = [Gu; c2d(feedback(C*P), Ts)]\n\nY = function (model, yh)\n    upper = [1.1, 500] # [plant output, total control signal]\n    lower = -upper\n    JuMP.@constraint(model, [i=1:size(yh, 2)], lower .<= yh[:, i] .<= upper)\nend\n\nalg = ConstrainedILC(; Gr_constraints, Gu_constraints, Q, R, A, Y, opt=OSQP.Optimizer, verbose=true, α=1)\nsol = ilc(prob, alg; actual)\nplot(sol)","category":"page"},{"location":"ConstrainedILC/","page":"ConstrainedILC","title":"ConstrainedILC","text":"This time, we do not achieve as small control error as before, but this is expected since the ILC algorithm now has additional constrained to respect. ","category":"page"},{"location":"ConstrainedILC/","page":"ConstrainedILC","title":"ConstrainedILC","text":"To plot the total control signal, we may simulate the augmented system. The input to this system is the reference signal r as well as the last adjustment signal a from the ILC algorithm (obtained from sol.A[end])","category":"page"},{"location":"ConstrainedILC/","page":"ConstrainedILC","title":"ConstrainedILC","text":"constrained_res = lsim([Gr_constraints Gu_constraints], [r; sol.A[end]])\nplot(constrained_res, title=[\"Plant output\" \"Total control signal\"]); hline!([1.1 500], l=(:red, :dash), lab=\"Constraint\")","category":"page"},{"location":"ConstrainedILC/","page":"ConstrainedILC","title":"ConstrainedILC","text":"We see that the control signal spikes at the sharp step in the reference, but it stays below the constraint 500. Nice.","category":"page"},{"location":"ConstrainedILC/#Docstring","page":"ConstrainedILC","title":"Docstring","text":"","category":"section"},{"location":"ConstrainedILC/","page":"ConstrainedILC","title":"ConstrainedILC","text":"ConstrainedILC","category":"page"},{"location":"ConstrainedILC/#IterativeLearningControl.ConstrainedILC","page":"ConstrainedILC","title":"IterativeLearningControl.ConstrainedILC","text":"ConstrainedILC(; Q, R, A, Y, Gr_constraints, Gu_constraints, opt, verbose=false, α)\n\nConstrained ILC algorithm from the paper \"On Robustness in Optimization-Based Constrained Iterative Learning Control\", Liao-McPherson and friends.\n\nThe use of this ILC algorithms requires the user to manually install and load the packages using JuMP, BlockArrays as well as a compatible solver (such as OSQP).\n\nSupports MIMO systems.\n\nFields:\n\nQ: Error penalty matrix, e.g., Q = I(ny)\nR: Feedforward penalty matrix, e.g., R = I(nu)\nA: A function of (model, a) that adds constraints to the optimization problem. a is a size (nu, N) matrix of optimization variables that determines the optimized ILC input. See example below. \nY: A function of (model, yh) that adds constraints to the optimization problem. yh is a size (ny, N) matrix of predicted plant outputs. See example below\nopt: A JuMP-compatible optimizer, e.g., OSQP.Optimizer\nα: Step size, should be smaller than 2. Smaller step sizes lead to more robust progress but slower convergence. Use a small step size if the model is highly uncertain.\nverbose: If true, print solver output\nGr_constraints: If provided, this is the closed-loop transfer function from reference to constrained outputs. If not provided, the constrained outputs are assumed to be equal to the plant outputs.\nGu_constraints: If provided, this is the closed-loop transfer function from plant input to constrained outputs. If not provided, the constrained outputs are assumed to be equal to the plant outputs.\n\nExample\n\nusing IterativeLearningControl, OSQP, JuMP, BlockArrays, ControlSystemsBase\n\n# Define Gr and Gu\n\nQ = 1000I(Gr.ny)\nR = 0.001I(Gu.nu)\n\nA = function (model, a) # Constrain the ILC input to the range [-25, 25]\n    l,u = (-25ones(Gu.nu), 25ones(Gu.nu))\n    JuMP.@constraint(model, [i=1:size(a, 2)], l .<= a[:, i] .<= u)\nend\n\nY = function (model, yh) # Constrain the predicted output to the range [-1.1, 1.1]\n    l,u = -1.1ones(Gr.ny), 1.1ones(Gr.ny)\n    JuMP.@constraint(model, [i=1:size(yh, 2)], l .<= yh[:, i] .<= u)\nend\n\nalg = ConstrainedILC(; Q, R, A, Y, opt=OSQP.Optimizer, verbose=true, α=1)\n\nTo constrain the total plant input, i.e., the sum of the ILC feedforward and the output of the feedback controller, add outputs corresponding to this signal to the models Gr, Gu, for example\n\nGr_constraints = [Gr; feedback(C, P)]\nGu_constraints = [Gu; feedback(1, C*P)]\n\nand constrain this output in the function Y above.\n\n\n\n\n\n","category":"type"},{"location":"ModelFreeILC/#ModelFreeILC","page":"ModelFreeILC","title":"ModelFreeILC","text":"","category":"section"},{"location":"ModelFreeILC/","page":"ModelFreeILC","title":"ModelFreeILC","text":"This ILC scheme is completely model free and works for nonlinear and time varying MIMO systems. The algorithm is described in the paper \"Model-free Gradient Iterative Learning Control for Non-linear Systems\" by Huo and friends.","category":"page"},{"location":"ModelFreeILC/","page":"ModelFreeILC","title":"ModelFreeILC","text":"The algorithm works by performing 3 experiments per ILC iteration","category":"page"},{"location":"ModelFreeILC/","page":"ModelFreeILC","title":"ModelFreeILC","text":"One rollout with the current ILC signal, G(a)\nOne rollout with the mean of the current ILC signal, G(hat a)\nOne rollout with the mean perturbed by a multiple of the time-reversed tracking error from experiment 1, G(hat a + alpha tildee). This allows us to compute an estimate of the gradient for a quadratic cost model.","category":"page"},{"location":"ModelFreeILC/","page":"ModelFreeILC","title":"ModelFreeILC","text":"Above, tildecdot denotes time reversal and hatcdot denotes the mean of a signal. G(a) denotes applying dynamic system G to signal a, i.e., performing an experiment on G with a as input.","category":"page"},{"location":"ModelFreeILC/","page":"ModelFreeILC","title":"ModelFreeILC","text":"The update to the ILC adjustment signal a is then computed as","category":"page"},{"location":"ModelFreeILC/","page":"ModelFreeILC","title":"ModelFreeILC","text":"a_k+1 = a_k - fracbetaalpha widetildebig( G(hat a + alpha tildee) - G(hat a) big)","category":"page"},{"location":"ModelFreeILC/","page":"ModelFreeILC","title":"ModelFreeILC","text":"The parameter alpha controls the size of the \"finite-difference perturbation\" and beta is the learning step size. ","category":"page"},{"location":"ModelFreeILC/","page":"ModelFreeILC","title":"ModelFreeILC","text":"Experiment number 3 that uses the time-reversed tracking error gives the algorithm \"foresight\" in a similar fashion to how HeuristicILC uses a non-causal learning-rate filter L.","category":"page"},{"location":"ModelFreeILC/#Example","page":"ModelFreeILC","title":"Example","text":"","category":"section"},{"location":"ModelFreeILC/","page":"ModelFreeILC","title":"ModelFreeILC","text":"This example mirrors that of HeuristicILC, we create the system model and feedback controller here without any explanation, and refer to the HeuristicILC example for those details","category":"page"},{"location":"ModelFreeILC/","page":"ModelFreeILC","title":"ModelFreeILC","text":"using IterativeLearningControl, ControlSystemsBase, Plots\n\nfunction double_mass_model(; \n                Jm = 1,   # motor inertia\n                Jl = 1,   # load inertia\n                k  = 100, # stiffness\n                c0 = 1,   # motor damping\n                c1 = 1,   # transmission damping\n                c2 = 1,   # load damping\n)\n\n    A = [\n        0.0 1 0 0\n        -k/Jm -(c1 + c0)/Jm k/Jm c1/Jm\n        0 0 0 1\n        k/Jl c1/Jl -k/Jl -(c1 + c2)/Jl\n    ]\n    B = [0, 1/Jm, 0, 0]\n    C = [1 0 0 0]\n    ss(A, B, C, 0)\nend\n\n# Continuous\nP    = double_mass_model(Jl = 1)\nPact = double_mass_model(Jl = 1.5) # 50% more load than modeled\nC    = pid(10, 1, 1, form = :series) * tf(1, [0.02, 1])\n\nTs = 0.02 # Sample time\nGr = c2d(feedback(P*C), Ts)       |> tf\nGu = c2d(feedback(P, C), Ts)\nGract = c2d(feedback(Pact*C), Ts)\nGuact = c2d(feedback(Pact, C), Ts)\n\nT = 3pi    # Duration\nt = 0:Ts:T # Time vector\nfunction funnysin(t)\n    x = sin(t)\n    s,a = sign(x), abs(x)\n    y = s*((a + 0.01)^0.2 - 0.01^0.2)\n    t > 2π ? sign(y) : y\nend\nr = funnysin.(t)' |> Array # Reference signal","category":"page"},{"location":"ModelFreeILC/","page":"ModelFreeILC","title":"ModelFreeILC","text":"Next, we define the ILCProblem and create the learning algorithm object OptimizationILC","category":"page"},{"location":"ModelFreeILC/","page":"ModelFreeILC","title":"ModelFreeILC","text":"prob = ILCProblem(; r, Gr, Gu)\nactual = ILCProblem(; r, Gr=Gract, Gu=Guact)\n\nalg = ModelFreeILC(1, 500)\nsol = ilc(prob, alg; actual, iters=10)\nplot(sol)","category":"page"},{"location":"ModelFreeILC/","page":"ModelFreeILC","title":"ModelFreeILC","text":"The result looks good, and since this algorithm is completely model free, we ran it directly on the \"actual\" dynamics without considering how it performs when using the model, like we did in the other examples. Keep in mind that this algorithm internally performs 3 rollouts (experiments) for each ILC iteration, so the experimental complexity is 3x of the other algorithms. To show all the intermediate input signals, we use the keyword argument store_all=true when calling ilc.","category":"page"},{"location":"ModelFreeILC/","page":"ModelFreeILC","title":"ModelFreeILC","text":"sol = ilc(prob, alg; actual, iters=10, store_all=true)\nplot(sol)","category":"page"},{"location":"ModelFreeILC/","page":"ModelFreeILC","title":"ModelFreeILC","text":"We now see the total number of rollouts performed. The tracking error now appears to have a non-monotonic behavior, which is expected since the intermediate rollouts apply a signal designed to estimate a gradient rather than minimizing the tracking error.","category":"page"},{"location":"ModelFreeILC/#Docstring","page":"ModelFreeILC","title":"Docstring","text":"","category":"section"},{"location":"ModelFreeILC/","page":"ModelFreeILC","title":"ModelFreeILC","text":"ModelFreeILC","category":"page"},{"location":"ModelFreeILC/#IterativeLearningControl.ModelFreeILC","page":"ModelFreeILC","title":"IterativeLearningControl.ModelFreeILC","text":"ModelFreeILC\n\nA model-free ILC scheme that works for linear, nonlinear systems and time-varying systems. The algorithm is described in the paper \"Model-free Gradient Iterative Learning Control for Non-linear Systems\" by Huo and friends.\n\nnote: Note\nThis algorithm requires three rollouts per ILC iteration and is not yet compatible with compute_input. When the ILCSolution is plotted, the number of actual rollouts performed is thus three times then number of ILC iterations shown in the plot (unless store_all=true in which case the true number of experiments is shown).\n\nFor non-square MIMO systems, this algorithm can only operate on the reference signal, i.e., with G_u = G_r in the ILCProblem. This is because the algorithm adds a scaled version of the tracking error to the ILC adjustment signal, and the two must thus be of compatible dimensions.\n\nWhen this algorithm is used, an additional keyword argument to the function ilc is available, store_all. If set to store_all = true, the returned solution object will contain all intermediate plant responses, errors and ILC inputs. This is useful for debugging and plotting.\n\nSee also GradientILC for the model-based version of this algorithm. The model-based version only requires a single rollout per iteration.\n\nFields:\n\nα: Perturbation size. An intermediate experiment with α e as input will be performed to compute the gradient. A value around 1 is a good start.\nβ: Step size.\n\n\n\n\n\n","category":"type"},{"location":"manual/#Manual-ILC-iterations","page":"Manual ILC iterations","title":"Manual ILC iterations","text":"","category":"section"},{"location":"manual/","page":"Manual ILC iterations","title":"Manual ILC iterations","text":"To perform ILC on a physical system, we need to repeatedly apply an ILC signal to our system under test, record the result, and compute a new ILC signal. The function ilc that is used in the examples in this documentation performs all these steps internally, but using a simulation model of the system. To perform these steps manually, we need to do the following:","category":"page"},{"location":"manual/","page":"Manual ILC iterations","title":"Manual ILC iterations","text":"Initialize the algorithm using the function init. Also choose an initial ILC signal, typically all zeros, but may also be chosen as the result of a few ILC iterations on a simulated system.\nPerform an experiment on the system under test and record the resulting output y\nCompute the tracking error e = r - y\nCompute a new ILC input signal a using the function compute_input\nRepeat steps 2-4 until the desired performance is achieved.\nEnjoy sweet tracking performance, maybe also tell your mother about it.","category":"page"},{"location":"manual/","page":"Manual ILC iterations","title":"Manual ILC iterations","text":"The function workspace = init(prob, alg) takes the specification of the ILC problem and the chosen algorithm and returns a workspace object with problem-specific things the algorithm needs to run. ","category":"page"},{"location":"manual/","page":"Manual ILC iterations","title":"Manual ILC iterations","text":"The function a = compute_input(prob, alg, workspace, a, e) takes the problem, algorithm, the workspace object created by init, the previous ILC input signal a_k and the tracking error e = r - y and returns a new ILC input signal a_k+1.","category":"page"},{"location":"manual/#Docstrings","page":"Manual ILC iterations","title":"Docstrings","text":"","category":"section"},{"location":"manual/","page":"Manual ILC iterations","title":"Manual ILC iterations","text":"init\ncompute_input","category":"page"},{"location":"manual/#IterativeLearningControl.init","page":"Manual ILC iterations","title":"IterativeLearningControl.init","text":"workspace = init(prob, alg)\n\nInitialize the ILC algorithm. This function is called internally by the funciton ilc but manual iterations require the user to initialize the workspace explicitly.\n\n\n\n\n\n","category":"function"},{"location":"manual/#IterativeLearningControl.compute_input","page":"Manual ILC iterations","title":"IterativeLearningControl.compute_input","text":"compute_input(prob, alg::ILCAlgorithm, workspace, a, e)\n\nCompute the next ILC input using the learning rule\n\nArguments:\n\nalg: The ILC algorithm\nworkspace: A workspace created by calling init on the algorithm: workspace = init(prob, alg).\na: Previous ILC input\ne: Error r - y\n\n\n\n\n\n","category":"function"},{"location":"non_lti/#Nonlinear-and-time-varying-systems","page":"Nonlinear and time-varying systems","title":"Nonlinear and time varying systems","text":"","category":"section"},{"location":"non_lti/","page":"Nonlinear and time-varying systems","title":"Nonlinear and time-varying systems","text":"Most algorithms (except HeuristicILC) work for nonlinear and/or time varying systems.","category":"page"},{"location":"non_lti/#Linear-time-varying-systems-(LTV)","page":"Nonlinear and time-varying systems","title":"Linear time-varying systems (LTV)","text":"","category":"section"},{"location":"non_lti/","page":"Nonlinear and time-varying systems","title":"Nonlinear and time-varying systems","text":"To construct an LTV system model, use the constructor LTVSystem.","category":"page"},{"location":"non_lti/","page":"Nonlinear and time-varying systems","title":"Nonlinear and time-varying systems","text":"LTVSystem","category":"page"},{"location":"non_lti/#IterativeLearningControl.LTVSystem","page":"Nonlinear and time-varying systems","title":"IterativeLearningControl.LTVSystem","text":"LTVSystem(A::Array{T, 3}, B::Array{T, 3}, C::Array{T, 3}, D::Array{T, 3}, Ts)\n\nConstruct a time-varying system from the state-space matrices A, B, C, D and sampling time Ts.\n\nArguments:\n\nA: A matrix of size (nx, nx, N) where nx is the state dimension and N is the number of time points.\nB: A matrix of size (nx, nu, N) where nu is the number of inputs.\nC: A matrix of size (ny, nx, N) where ny is the number of outputs.\nD: A matrix of size (ny, nu, N).\nTs: The sampling time.\n\n\n\n\n\nLTVSystem(syss::Vector{StateSpace{Discrete}})\n\nConstruct a time-varying system from a vector of LTI statspace models.\n\n\n\n\n\n","category":"type"},{"location":"non_lti/","page":"Nonlinear and time-varying systems","title":"Nonlinear and time-varying systems","text":"LTVSystems can also be obtained by calling IterativeLearningControl.linearize on a NonlinearSystem.","category":"page"},{"location":"non_lti/","page":"Nonlinear and time-varying systems","title":"Nonlinear and time-varying systems","text":"LTV models are used in exactly the same way for ILC as LTI models.","category":"page"},{"location":"non_lti/#Nonlinear-systems","page":"Nonlinear and time-varying systems","title":"Nonlinear systems","text":"","category":"section"},{"location":"non_lti/","page":"Nonlinear and time-varying systems","title":"Nonlinear and time-varying systems","text":"To construct a nonlinear system model, use the constructor NonlinearSystem.","category":"page"},{"location":"non_lti/","page":"Nonlinear and time-varying systems","title":"Nonlinear and time-varying systems","text":"NonlinearSystem","category":"page"},{"location":"non_lti/#IterativeLearningControl.NonlinearSystem","page":"Nonlinear and time-varying systems","title":"IterativeLearningControl.NonlinearSystem","text":"NonlinearSystem{F, G}\n\nA model representation for a discrete-time nonlinear systems on the form\n\nbeginalign\nx_k+1 = f(x_k a_k r_k p t) \ny_k = g(x_k a_k r_k p t)\nendalign\n\nwhere x is the state, a is ILC adjustment signal, r is the reference, p is a parameter vector and t is the time.\n\nIf you have continuous-time dynamics it must be discretized first, see, e.g., the package SeeToDee.jl for options.\n\nFields:\n\nf::F: The dynamics function\ng::G: The output function\nnx::Int: The number of state variables\nny::Int: The number of outputs\nna::Int: The number of ILC adjustment inputs\nTs::Float64: The sample time\n\n\n\n\n\n","category":"type"},{"location":"non_lti/","page":"Nonlinear and time-varying systems","title":"Nonlinear and time-varying systems","text":"To run ILC on a NonlinearSystem, construct a NonlinearILCProblem rather than the standard ILCProblem.","category":"page"},{"location":"non_lti/","page":"Nonlinear and time-varying systems","title":"Nonlinear and time-varying systems","text":"NonlinearILCProblem","category":"page"},{"location":"non_lti/#IterativeLearningControl.NonlinearILCProblem","page":"Nonlinear and time-varying systems","title":"IterativeLearningControl.NonlinearILCProblem","text":"NonlinearILCProblem\n\nA nonlinear version of ILCProblem\n\nFields:\n\nr: The reference trajectory, a matrix of size (ny, N) where ny is the number of outputs and N is the number of time points.\nmodel: An instance of NonlinearSystem\nx0: The initial state\np: An optional parameter object that will be passed to the dynamics\n\n\n\n\n\n","category":"type"},{"location":"non_lti/","page":"Nonlinear and time-varying systems","title":"Nonlinear and time-varying systems","text":"Otherwise everything else behaves the same, i.e., you still call the function ilc to run the iterations and the function compute_input to compute the ILC input signal manually.","category":"page"},{"location":"non_lti/#Linearization","page":"Nonlinear and time-varying systems","title":"Linearization","text":"","category":"section"},{"location":"non_lti/","page":"Nonlinear and time-varying systems","title":"Nonlinear and time-varying systems","text":"A nonlinear system may be linearized around an operating point or around a trajectory using the function IterativeLearningControl.linearize. This function returns a StateSpace model or an LTVSystem.","category":"page"},{"location":"non_lti/","page":"Nonlinear and time-varying systems","title":"Nonlinear and time-varying systems","text":"When a NonlinearILCProblem is solved, this is performed automatically in the method of compute_input associated with the chosen algorithm (if the algorithm is model based).","category":"page"},{"location":"#IterativeLearningControl","page":"Home","title":"IterativeLearningControl","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"(Image: Build Status)","category":"page"},{"location":"#What-is-ILC?","page":"Home","title":"What is ILC?","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"ILC can be thought of as either","category":"page"},{"location":"","page":"Home","title":"Home","text":"a simple reinforcement-learning (RL) strategy, or\na method to solve open-loop optimal control problems.","category":"page"},{"location":"","page":"Home","title":"Home","text":"ILC is suitable in situations where a repetitive task is to be performed multiple times, and disturbances acting on the system are also repetitive and predictable but  may be unknown. Multiple versions of ILC exists, of which we support a few that are listed below. When ILC iterations are performed by running experiments on a physical system, ILC resembles episode-based reinforcement learning (or adaptive control), while if a model is used to simulate the experiments, we can instead think of ILC as a way to solve optimal control problems (trajectory optimization).","category":"page"},{"location":"#Algorithms","page":"Home","title":"Algorithms","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"We support the following algorithms:","category":"page"},{"location":"","page":"Home","title":"Home","text":"using PrettyTables, Markdown\n\nheader = [\"Algorithm\", \"Model based\", \"MIMO\", \"Nonlinear\", \"Cost function\", \"Constraints\", \"Computational complexity\", \"Experimental complexity\"]\n\ndata = [\n    \"HeuristicILC\"        \"🔶\" \"🟥\" \"🟥\" \"🟥\" \"🟥\" \"Low (filtering)\"    \"Low (1)\"\n    \"OptimizationILC\"     \"🟢\" \"🟢\" \"🟢\" \"🟢\" \"🟥\" \"Mid (Cholesky)\"     \"Low (1)\"\n    \"ConstrainedILC\"      \"🟢\" \"🟢\" \"🟥\" \"🟢\" \"🟢\" \"High (QP)\"          \"Low (1)\"\n    \"GradientILC\"         \"🟢\" \"🟢\" \"🟢\" \"🔶\" \"🟥\" \"Low\"                \"Low (1)\"\n    \"ModelFreeILC\"        \"🟥\" \"🟢\" \"🟢\" \"🔶\" \"🟥\" \"Low\"                \"High (3)\"\n]\n\nio = IOBuffer()\ntab = pretty_table(io, data; header, tf=tf_html_default)\ntab_algs = String(take!(io)) |> HTML","category":"page"},{"location":"","page":"Home","title":"Home","text":"tab_algs # hide","category":"page"},{"location":"","page":"Home","title":"Home","text":"Each algorithm has an associated documentation page available from the menu on the left.","category":"page"},{"location":"#Comments","page":"Home","title":"Comments","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"The 🔶 used for HeuristicILC indicates that the learning filters may be optionally chosen in a model-based way, but heuristic choices are also possible.\nMost algorithms work for time varying and/or nonlinear systems by considering linearizations around the last recorded trajectory. \nThe gradient-based algorithms, like GradientILC and ModelFreeILC can easily be modified to include a penalty on the size of the adjustment signal a.\nAll algorithms can be trivially modified to add the Q filter present in HeuristicILC in order to improve robustness to measurement noise and model errors.","category":"page"},{"location":"#Terminology","page":"Home","title":"Terminology","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"In this documentation, we will refer to the following signals and (discrete-time) transfer functions","category":"page"},{"location":"","page":"Home","title":"Home","text":"y is an output to be controlled\nr is a reference signal that we want y to track.\nu is the control signal\na is the ILC adjustment signal which may be added to either the reference or directly to the plant input.\nP(z) is the plant, i.e., the system to control\nC(z) is a feedback controller\nG_r(z) is the closed-loop transfer function from r to y: PC  (1 + PC)\nG_u(z) is the closed-loop transfer function from u to y: P  (1 + PC)","category":"page"}]
}
