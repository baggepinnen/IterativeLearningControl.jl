var documenterSearchIndex = {"docs":
[{"location":"HeuristicILC/#Heuristic-ILC","page":"HeuristicILC","title":"Heuristic ILC","text":"","category":"section"},{"location":"HeuristicILC/","page":"HeuristicILC","title":"HeuristicILC","text":"A heuristic ILC scheme that operates by adjusting the reference signal r typically looks something like this, at ILC iteration k:","category":"page"},{"location":"HeuristicILC/","page":"HeuristicILC","title":"HeuristicILC","text":"beginaligned\ny_k(t) = G_r(q) big(r(t) + a_k(t) big) \ne_k(t) = r(t) - y_k(t) \na_k(t) = Q(q) big( a_k-1(t) + L(q) e_k-1(t) big)\nendaligned","category":"page"},{"location":"HeuristicILC/","page":"HeuristicILC","title":"HeuristicILC","text":"where q is the time-shift operator, G_r(q) is the transfer function from the reference r to the output y, i.e, typically a closed-loop transfer function, e_k is the control error and a_k is the ILC adjustment signal, an additive correction to the reference that is learned throughout the ILC iterations in order to minimize the control error. Q(q) and L(q) are stable filters that control the learning dynamics. Interestingly, these filters does not have to be causal since they operate on the signals e and a between ILC iterations, when the whole signals are available at once for acausal filtering. ","category":"page"},{"location":"HeuristicILC/","page":"HeuristicILC","title":"HeuristicILC","text":"If the ILC instead operates by adding directly to the the plant input u, the first equation above is replaced by","category":"page"},{"location":"HeuristicILC/","page":"HeuristicILC","title":"HeuristicILC","text":"y_k(t) = G_r(q) r(t) + G_u(q) a_k(t)","category":"page"},{"location":"HeuristicILC/","page":"HeuristicILC","title":"HeuristicILC","text":"where the transfer function G_u(q) is the closed-loop transfer function from plant input to the output y.","category":"page"},{"location":"HeuristicILC/","page":"HeuristicILC","title":"HeuristicILC","text":"In simulation (the rollout y_k = G_r(q) (r + a_k) is simulated), this scheme is nothing other than an open-loop optimal-control strategy, while if y_k = G_r(q) (r + a_k) amounts to performing an actual experiment on a process, ILC turns into episode-based reinforcement learning or adaptive control.","category":"page"},{"location":"HeuristicILC/","page":"HeuristicILC","title":"HeuristicILC","text":"The system to control in this example is a double-mass system with a spring and damper in between. This system is a common model of a servo system where one mass represents the motor and the other represents the load. The spring and damper represents a flexible transmission between them. We will create two instances of the system model. P represents the nominal model, whereas P_act represents the actual (unknown) dynamics. This simulates a model-based approach where there is a slight error in the model. The error will lie in the mass of the load, simulating, e.g., that the motor is driving a heavier load than specified. ","category":"page"},{"location":"HeuristicILC/#Example","page":"HeuristicILC","title":"Example","text":"","category":"section"},{"location":"HeuristicILC/#System-model-and-controller","page":"HeuristicILC","title":"System model and controller","text":"","category":"section"},{"location":"HeuristicILC/","page":"HeuristicILC","title":"HeuristicILC","text":"using Plots\ndefault(size=(800,800))","category":"page"},{"location":"HeuristicILC/","page":"HeuristicILC","title":"HeuristicILC","text":"using IterativeLearningControl, ControlSystemsBase, Plots\n\nfunction double_mass_model(; \n                Jm = 1,   # motor inertia\n                Jl = 1,   # load inertia\n                k  = 100, # stiffness\n                c0 = 1,   # motor damping\n                c1 = 1,   # transmission damping\n                c2 = 1,   # load damping\n)\n\n    A = [\n        0.0 1 0 0\n        -k/Jm -(c1 + c0)/Jm k/Jm c1/Jm\n        0 0 0 1\n        k/Jl c1/Jl -k/Jl -(c1 + c2)/Jl\n    ]\n    B = [0, 1/Jm, 0, 0]\n    C = [1 0 0 0]\n    ss(A, B, C, 0)\nend\n\n# Continuous\nP    = double_mass_model(Jl = 1)\nPact = double_mass_model(Jl = 1.5) # 50% more load than modeled\nC  = pid(10, 1, 1, form = :series) * tf(1, [0.02, 1])\nTs = 0.02 # Sample time\nz = tf(\"z\", Ts)\n\n\n# Discrete\nGr = c2d(feedback(P*C), Ts)       |> tf\nGu = c2d(feedback(P, C), Ts)\nGract = c2d(feedback(Pact*C), Ts)\nGuact = c2d(feedback(Pact, C), Ts)\n\nbodeplot([Gr, Gract], lab=[\"G model\" \"G actual\"], plotphase=false)","category":"page"},{"location":"HeuristicILC/","page":"HeuristicILC","title":"HeuristicILC","text":"We will design a PID controller with a filter for the system, the controller is poorly tuned and not very good at tracking fast reference steps, in practice, one would likely design a feedforward controller as well to improve upon this, but for now we'll stick with the simple feedback controller.","category":"page"},{"location":"HeuristicILC/","page":"HeuristicILC","title":"HeuristicILC","text":"C  = pid(10, 1, 1, form = :series) * tf(1, [0.02, 1])\nTs = 0.02 # Sample time\nplot(step(Gr, 10), title=\"Closed-loop step response\", lab=\"model\")\nplot!(step(Gract, 10), lab=\"actual\")","category":"page"},{"location":"HeuristicILC/#Reference-trajectory","page":"HeuristicILC","title":"Reference trajectory","text":"","category":"section"},{"location":"HeuristicILC/","page":"HeuristicILC","title":"HeuristicILC","text":"Next up we design a reference trajectory and simulate the actual closed-loop dynamics.","category":"page"},{"location":"HeuristicILC/","page":"HeuristicILC","title":"HeuristicILC","text":"T = 3pi    # Duration\nt = 0:Ts:T # Time vector\nfunction funnysin(x)\n    x = sin(x)\n    s,a = sign(x), abs(x)\n    s*((a + 0.01)^0.2 - 0.01^0.2)\nend\nr = funnysin.(t)' |> Array # Reference signal\n\nres = lsim(Gract, r, t)\nplot(res, plotu=true, layout=1, sp=1, title=\"Closed-loop simulation with actual dynamics\", lab=[\"y\" \"r\"])","category":"page"},{"location":"HeuristicILC/","page":"HeuristicILC","title":"HeuristicILC","text":"Performance is poor.. Enter ILC!","category":"page"},{"location":"HeuristicILC/#Choosing-filters","page":"HeuristicILC","title":"Choosing filters","text":"","category":"section"},{"location":"HeuristicILC/","page":"HeuristicILC","title":"HeuristicILC","text":"The next step is to define the ILC filters Q(z) and L(z).","category":"page"},{"location":"HeuristicILC/","page":"HeuristicILC","title":"HeuristicILC","text":"The filter L(q) acts as a frequency-dependent step size. To make the procedure take smaller steps, simply scale L by a constant < 1. Scaling down L makes the learning process slower but more robust. A heuristic choice of L is some form of scaled lookahead, such as 05z^l where l geq 0 is the number of samples lookahead. A model-based approach may use some form of inverse of the system model, which is what we will use here. [nonlinear]","category":"page"},{"location":"HeuristicILC/","page":"HeuristicILC","title":"HeuristicILC","text":"[nonlinear]: Inverse models can be formed also for some nonlinear systems. ModelingToolkit.jl is particularly well suited for inverting models due to its acausal nature.","category":"page"},{"location":"HeuristicILC/","page":"HeuristicILC","title":"HeuristicILC","text":"The filter Q(z) acts to make the procedure robust w.r.t. noise and modeling errors. Q has a final say over what frequencies appear in a and it's good to choose Q with low-pass properties. Q will here be applied in zero-phase mode, so the effective transfer function will be Q(z)Q(z).","category":"page"},{"location":"HeuristicILC/","page":"HeuristicILC","title":"HeuristicILC","text":"z = tf(\"z\", Ts)\nQ = c2d(tf(1, [0.05, 1]), Ts)\n# L = 0.9z^1 # A more conservative and heuristic choice\nL = 0.5inv(Gr) # Make the scaling factor smaller to take smaller steps\n\nalg = HeuristicILC(Q, L, :ref)\nnothing # hide","category":"page"},{"location":"HeuristicILC/","page":"HeuristicILC","title":"HeuristicILC","text":"A theorem due to NorrlÃ¶f says that for the ILC iterations to converge, one needs to satisfy  1 - LG   Q^-1 which we can verify by looking at the Bode curves of the two sides of the inequality","category":"page"},{"location":"HeuristicILC/","page":"HeuristicILC","title":"HeuristicILC","text":"ilc_theorem(alg, Gr, tf(Gract))","category":"page"},{"location":"HeuristicILC/","page":"HeuristicILC","title":"HeuristicILC","text":"Above, we plotted this curve also for the actual dynamics. This is of course not possible in a real scenario where this is unknown, but one could plot it for multiple plausible models and verify that they are all below the boundary. See Uncertainty modeling using RobustAndOptimalControl.jl for guidance on this. Looking at the stability condition, it becomes obvious how making Q small where the model is uncertain is beneficial for robustness of the ILC scheme.","category":"page"},{"location":"HeuristicILC/#ILC-iteration","page":"HeuristicILC","title":"ILC iteration","text":"","category":"section"},{"location":"HeuristicILC/","page":"HeuristicILC","title":"HeuristicILC","text":"The next step is to implement the ILC scheme and run it:","category":"page"},{"location":"HeuristicILC/","page":"HeuristicILC","title":"HeuristicILC","text":"prob = ILCProblem(; r, Gr, Gu)\nsol = ilc(prob, alg)\nplot(sol)","category":"page"},{"location":"HeuristicILC/","page":"HeuristicILC","title":"HeuristicILC","text":"When running on the model, the result looks very good. We see that the tracking error in the last plot decreases rapidly and is much smaller after only a couple of iterations. We also note that the adjusted reference r+a has effectively been phase-advanced slightly to compensate for the lag in the system dynamics. This is an effect of the acausal filtering due to L = G_C^-1.","category":"page"},{"location":"HeuristicILC/","page":"HeuristicILC","title":"HeuristicILC","text":"How does it work on the \"actual\" dynamics? To simulate the effect of plant-model mismatch, one may provide a different instance of the ILCProblem using the actual keyword argument which is used to simulate the plant response. The ILC update will be performed using the plant model from prob, while simulated data will be acquired from the models in actual.","category":"page"},{"location":"HeuristicILC/","page":"HeuristicILC","title":"HeuristicILC","text":"actual = ILCProblem(; r, Gr=Gract, Gu=Guact)\nsol = ilc(prob, alg; actual)\nplot(sol)","category":"page"},{"location":"HeuristicILC/","page":"HeuristicILC","title":"HeuristicILC","text":"The result is subtly worse, but considering the rather big model error the result is still quite good. ","category":"page"},{"location":"HeuristicILC/#Assessing-convergence-under-uncertainty","page":"HeuristicILC","title":"Assessing convergence under uncertainty","text":"","category":"section"},{"location":"HeuristicILC/","page":"HeuristicILC","title":"HeuristicILC","text":"We can attempt at modeling the uncertainty we have in the plant using uncertain numbers from MonteCarloMeasurements.jl. This will allow us to asses whether our chosen filter fulfil the convergence criteria for all possible realizations of the uncertain plant.","category":"page"},{"location":"HeuristicILC/","page":"HeuristicILC","title":"HeuristicILC","text":"using MonteCarloMeasurements\nunsafe_comparisons(true)\nPact = double_mass_model(\n    Jl = 0.5..1.5, # Â± 50% load uncertainty\n    c1 = 0.8..1.2, # Â± 20% transmission damping uncertainty\n    c2 = 0.8..1.2, # Â± 20% load damping uncertainty\n) \nGract = c2d(feedback(Pact*C), Ts)\nw = exp10.(-2:0.01:2)\nilc_theorem(alg, Gr, tf(Gract); w)","category":"page"},{"location":"HeuristicILC/","page":"HeuristicILC","title":"HeuristicILC","text":"In this case, it looks like we're good to go!","category":"page"},{"location":"HeuristicILC/","page":"HeuristicILC","title":"HeuristicILC","text":"Learn more about modeling uncertainty in control systems under RobustAndOptimalControl: Uncertainty modeling.","category":"page"},{"location":"HeuristicILC/#Docstring","page":"HeuristicILC","title":"Docstring","text":"","category":"section"},{"location":"HeuristicILC/","page":"HeuristicILC","title":"HeuristicILC","text":"HeuristicILC","category":"page"},{"location":"HeuristicILC/#IterativeLearningControl.HeuristicILC","page":"HeuristicILC","title":"IterativeLearningControl.HeuristicILC","text":"HeuristicILC(  Q, L, location)        # Positional arguments\nHeuristicILC(; Q, L, location = :ref) # Keyword arguments\n\nApply the learning rule\n\nbeginaligned\ny_k(t) = G_r(q) big(r(t) + a_k(t) big) \ne_k(t) = r(t) - y_k(t) \na_k(t) = Q(q) big( a_k-1(t) + L(q) e_k-1(t) big)\nendaligned\n\nIf location = :input, the first equation above is replaced by\n\ny_k(t) = G_r(q) r(t) + G_u(q) a_k(t)\n\nA theorem due to NorrlÃ¶f says that for this ILC iterations to converge, one needs to satisfy\n\n 1 - LG   Q^-1\n\nwhich we can verify by looking at the plot produced by the ilc_theorem function.\n\nFields:\n\nQ(z): Robustness filter (discrete time). The filter will be applied both forwards and backwards in time (like filtfilt), and the effective filter transfer funciton is thus Q(z)Q(z).\nL(z): Learning filter (discrete time). This filter may be non-causal, for example L = G^-1 where G is the closed-loop transfer function.\nlocation: Either :ref or :input. If :ref, the ILC input is added to the reference signal, otherwise it is added to the input signal directly.\n\n\n\n\n\n","category":"type"},{"location":"OptimizationILC/#Docstring","page":"OptimizationILC","title":"Docstring","text":"","category":"section"},{"location":"OptimizationILC/","page":"OptimizationILC","title":"OptimizationILC","text":"OptimizationILC","category":"page"},{"location":"OptimizationILC/#IterativeLearningControl.OptimizationILC","page":"OptimizationILC","title":"IterativeLearningControl.OptimizationILC","text":"OptimizationILC(; Ï = 1e-3, Î» = 1e-3)\n\nOptimization-based linear ILC algorithm from NorrlÃ¶f's thesis. This algorithm applies the ILC feedforward signal directly to the plant input.\n\nArguments:\n\nÏ: Penalty on feedforward control action\nÎ»: Step size penalty\n\n\n\n\n\n","category":"type"},{"location":"api/#Exported-functions-and-types","page":"API","title":"Exported functions and types","text":"","category":"section"},{"location":"api/#Index","page":"API","title":"Index","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"","category":"page"},{"location":"api/#Docstrings","page":"API","title":"Docstrings","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"Modules = [IterativeLearningControl]","category":"page"},{"location":"api/#IterativeLearningControl.ILCProblem","page":"API","title":"IterativeLearningControl.ILCProblem","text":"ILCProblem\n\nFields:\n\nr: Reference signal\nGr: Closed-loop transfer function from reference to output\nGu: Closed-loop transfer function from plant input to output\n\n\n\n\n\n","category":"type"},{"location":"api/#IterativeLearningControl.ILCProblem-Tuple{}","page":"API","title":"IterativeLearningControl.ILCProblem","text":"ILCProblem(; r, Gr, Gu)\nILCProblem(; r, P, C)\n\nConstruct an ILCProblem given discrete-time transfer function models of either\n\nThe closed-loop transfer functions from reference to output and from plant input to output, or\nThe plant and controller transfer functions\n\nContinuous-time transfer functions can be discretized using the function ControlSystemsBase.c2d.\n\nr: Reference trajectory\nGr: Closed-loop transfer function from reference to output\nGu: Closed-loop transfer function from plant input to output\nP: Plant model\nC: Controller transfer function\n\n\n\n\n\n","category":"method"},{"location":"api/#IterativeLearningControl.ILCSolution","page":"API","title":"IterativeLearningControl.ILCSolution","text":"ILCSolution\n\nA structure representing the solution to an ILC problem. \n\nFields:\n\nY: Plant responses. Y[i] is the response during the ith iteration\nE: Errors. E[i] is the error during the ith iteration\nA: ILC inputs. A[i] is the ILC input during the ith iteration.\nprob: The ILCProblem that was solved\nalg: The ILCAlgorithm that was used\n\n\n\n\n\n","category":"type"},{"location":"api/#IterativeLearningControl.OptimizationILC-Tuple{}","page":"API","title":"IterativeLearningControl.OptimizationILC","text":"OptimizationILC(; Ï = 1e-3, Î» = 1e-3)\n\nOptimization-based linear ILC algorithm from NorrlÃ¶f's thesis. This algorithm applies the ILC feedforward signal directly to the plant input.\n\nArguments:\n\nÏ: Penalty on feedforward control action\nÎ»: Step size penalty\n\n\n\n\n\n","category":"method"},{"location":"api/#IterativeLearningControl.compute_input-Tuple{HeuristicILC, Any, Any, Any}","page":"API","title":"IterativeLearningControl.compute_input","text":"compute_input(alg::ILCAlgorithm, workspace, a, e)\n\nCompute the next ILC input using the learning rule\n\nArguments:\n\nalg: The ILC algorithm\nworkspace: A workspace created by calling init on the algorithm: workspace = init(prob, alg).\na: Previous ILC input\ne: Error r - y\n\n\n\n\n\n","category":"method"},{"location":"api/#IterativeLearningControl.hankel_operator-Tuple{LTISystem{<:Discrete}, Int64}","page":"API","title":"IterativeLearningControl.hankel_operator","text":"hankel(sys::LTISystem{<:Discrete}, N::Int)\n\nReturn a matrix operator H such that Hu^T = y^T where y = lsim(sys, u). H is a Hankel matrix containing the Markov parameters of the system (scaled impulse response).\n\n\n\n\n\n","category":"method"},{"location":"api/#IterativeLearningControl.hv-Tuple{Any}","page":"API","title":"IterativeLearningControl.hv","text":"A little helper function that takes a matrix with dimensions (nsignals, n_timepoints) and returns a reshaped vector version that is suitable for multiplying the Hankel operator obtained by calling hankel_operator or mv_hankel_operator.\n\n\n\n\n\n","category":"method"},{"location":"api/#IterativeLearningControl.ilc-Tuple{Any, Any}","page":"API","title":"IterativeLearningControl.ilc","text":"ilc(prob, alg; iters = 5, actual=prob)\n\nRun the ILC algorithm for iters iterations. Returns a ILCSolution structure.\n\nTo manually perform ILC iterations, see the functions\n\ninit\ncompute_input\n\nTo simulate the effect of plant-model mismatch, one may provide a different instance of the ILCProblem using the actual keyword argument which is used to simulate the plant response. The ILC update will be performed using the plant model from prob, while simulated data will be acquired from the plant models in the actual problem.\n\n\n\n\n\n","category":"method"},{"location":"api/#IterativeLearningControl.ilc_theorem","page":"API","title":"IterativeLearningControl.ilc_theorem","text":"ilc_theorem(alg::HeuristicILC, Gc, Gcact = nothing)\n\nPlot the stability boundary for the ILC algorithm.\n\nArguments:\n\nalg: Containing the filters Q and L\nGc: The closed-loop system from ILC signal to output. If alg.location = :ref, this is typically given by feedback(P*C) while if alg.location = :input, this is typically given by feedback(P, C).\nGcact: If provided, this is the \"actual\" closed-loop system which may be constructed using a different plant model than Gc. This is useful when trying to determine if the filter choises will lead to a robust ILC algorithm. Gc may be constructed using, e.g., uncertain parameters, see https://juliacontrol.github.io/RobustAndOptimalControl.jl/dev/uncertainty/ for more details.\n\n\n\n\n\n","category":"function"},{"location":"api/#IterativeLearningControl.init-Tuple{Any, Any}","page":"API","title":"IterativeLearningControl.init","text":"init(prob, alg)\n\nInitialize the ILC algorithm. This function is called internally by the funciton ilc but manual iterations require the user to initialize the workspace explicitly.\n\n\n\n\n\n","category":"method"},{"location":"api/#IterativeLearningControl.mv_hankel_operator","page":"API","title":"IterativeLearningControl.mv_hankel_operator","text":"mv_hankel_operator(sys::LTISystem{<:Discrete}, N::Int)\n\nReturn a matrix operator H such that y == reshape(H*vec(u'), :, sys.ny)' where y = lsim(sys, u). H is a block Hankel matrix containing the Markov parameters of the system (scaled impulse response).\n\nUse of this function requires the user to manually install and load the packages using JuMP, BlockArrays.\n\n\n\n\n\n","category":"function"},{"location":"ConstrainedILC/#Docstring","page":"ConstrainedILC","title":"Docstring","text":"","category":"section"},{"location":"ConstrainedILC/","page":"ConstrainedILC","title":"ConstrainedILC","text":"ConstrainedILC","category":"page"},{"location":"ConstrainedILC/#IterativeLearningControl.ConstrainedILC","page":"ConstrainedILC","title":"IterativeLearningControl.ConstrainedILC","text":"ConstrainedILC(; Q, R, U, Y, Gr_constraints, Gu_constraints, opt, verbose=false, Î±)\n\nConstrained ILC algorithm from the paper \"On Robustness in Optimization-Based Constrained Iterative Learning Control\", Liao-McPherson and friends.\n\nThe use of this ILC algorithms requires the user to manually install and load the packages using JuMP, BlockArrays as well as a compatible solver (such as OSQP).\n\nSupports MIMO systems.\n\nFields:\n\nQ: Error penalty matrix, e.g., Q = I(ny)\nR: Feedforward penalty matrix, e.g., R = I(nu)\nU: A function of (model, a) that adds constraints to the optimization problem. a is a size (nu, N) matrix of optimization variables that determines the optimized ILC input. See example below. \nY: A function of (model, yh) that adds constraints to the optimization problem. yh is a size (ny, N) matrix of predicted plant outputs. See example below\nopt: A JuMP-compatible optimizer, e.g., OSQP.Optimizer\nÎ±: Step size, should be smaller than 2. Smaller step sizes lead to more robust progress but slower convergence. Use a small step size if the model is highly uncertain.\nverbose: If true, print solver output\nGr_constraints: If provided, this is the closed-loop transfer function from reference to constrained outputs. If not provided, the constrained outputs are assumed to be equal to the plant outputs.\nGu_constraints: If provided, this is the closed-loop transfer function from plant input to constrained outputs. If not provided, the constrained outputs are assumed to be equal to the plant outputs.\n\nExample\n\nusing IterativeLearningControl, OSQP, JuMP, BlockArrays, ControlSystemsBase\n\n# Define Gr and Gu\n\nQ = 1000I(Gr.ny)\nR = 0.001I(Gu.nu)\n\nU = function (model, a) # Constrain the ILC input to the range [-25, 25]\n    l,u = (-25ones(Gu.nu), 25ones(Gu.nu))\n    JuMP.@constraint(model, [i=1:size(a, 2)], l .<= a[:, i] .<= u)\nend\n\nY = function (model, yh) # Constrain the predicted output to the range [-1.1, 1.1]\n    l,u = -1.1ones(Gr.ny), 1.1ones(Gr.ny)\n    JuMP.@constraint(model, [i=1:size(yh, 2)], l .<= yh[:, i] .<= u)\nend\n\nalg = ConstrainedILC(; Q, R, U, Y, opt=OSQP.Optimizer, verbose=true, Î±=1)\n\nTo constrain the total plant input, i.e., the sum of the ILC feedforward and the output of the feedback controller, add outputs corresponding to this signal to the models Gr, Gu, for example\n\nGr_constraints = [Gr; feedback(C, P)]\nGu_constraints = [Gu; feedback(1, C*P)]\n\nand constrain this output in the function Y above.\n\n\n\n\n\n","category":"type"},{"location":"#IterativeLearningControl","page":"Home","title":"IterativeLearningControl","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"(Image: Build Status)","category":"page"},{"location":"#What-is-ILC?","page":"Home","title":"What is ILC?","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"ILC can be thought of as a simple reinforcement-learning strategy that is suitable in situations where a repetitive task is to be performed multiple times, and disturbances acting on the system are also repetitive and predictable but unknown. Multiple versions of ILC exists, of which we support a few that are listed below.","category":"page"},{"location":"#Algorithms","page":"Home","title":"Algorithms","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"We support the following algorithms:","category":"page"},{"location":"","page":"Home","title":"Home","text":"using PrettyTables, Markdown\n\nheader = [\"Algorithm\", \"Model based\", \"MIMO\", \"Cost function\", \"Constraints\", \"Computational complexity\"]\n\ndata = [\n    \"HeuristicILC\"        \"ð¶\" \"ð¥\" \"ð¥\" \"ð¥\" \"Low ð (filtering)\"\n    \"OptimizationILC\"     \"ð¢\" \"ð¥\" \"ð¢\" \"ð¥\" \"Medium ð¤ (matrix factorization)\"\n    \"ConstrainedILC\"      \"ð¢\" \"ð¢\" \"ð¢\" \"ð¢\" \"High ðï¸ (quadratic program)\"\n]\n\nio = IOBuffer()\ntab = pretty_table(io, data; header, tf=tf_html_default)\ntab_algs = String(take!(io)) |> HTML","category":"page"},{"location":"","page":"Home","title":"Home","text":"tab_algs # hide","category":"page"},{"location":"","page":"Home","title":"Home","text":"Each algorithm has an associated documentation page available from the menu on the left. The ð¶ used for HeuristicILC indicates that the learning filters may be optionally chosen in a model-based way, but heuristic choices are also possible.","category":"page"},{"location":"#Terminology","page":"Home","title":"Terminology","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"In this documentation, we will refer to the following signals and (discrete-time) transfer functions","category":"page"},{"location":"","page":"Home","title":"Home","text":"y is an output to be controlled\nr is a reference signal that we want y to track.\nu is the control signal\na is the ILC adjustment signal which may be added to either the reference or directly to the plant input.\nP(z) is the plant, i.e., the system to control\nC(z) is a feedback controller\nG_r(z) is the closed-loop transfer function from r to y: PC  (1 + PC)\nG_u(z) is the closed-loop transfer function from u to y: P  (1 + PC)","category":"page"}]
}
